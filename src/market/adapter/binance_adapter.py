# binance_adapter.py
import asyncio
from decimal import Decimal
from datetime import datetime, timezone
from typing import List, Dict, Deque, Optional, Any, Tuple
from collections import defaultdict, deque
import time
import traceback

from logger.logger import get_logger
from .base_adapter import BaseAdapter
from ..service.ws_connector import WebSocketConnector
from ..service.rest_connector import RESTConnector
from ..core.data_models import MarketData, OrderBook, OrderBookLevel, ExchangeType, MarketType, TradeTick

logger = get_logger()

'''
å¸å®‰å®˜æ–¹æŒ‡å—ï¼š
    å¦‚ä½•æ­£ç¡®ç®¡ç†æœ¬åœ°è®¢å•ç°¿

        1. å»ºç«‹ WebSocket è¿æ¥è‡³ wss://stream.binance.com:9443/ws/bnbbtc@depthã€‚

        2. ç¼“å†²ä»æ•°æ®æµæ¥æ”¶åˆ°çš„æ‰€æœ‰äº‹ä»¶ã€‚è®°å½•ä½ æ”¶åˆ°çš„ç¬¬ä¸€ä¸ªäº‹ä»¶çš„ U å€¼ã€‚

        3. é€šè¿‡ REST API è·å–æ·±åº¦å¿«ç…§ï¼šhttps://api.binance.com/api/v3/depth?symbol=BNBBTC&limit=5000ã€‚

        4. å¦‚æœå¿«ç…§ä¸­çš„ lastUpdateId ä¸¥æ ¼å°äº ç¬¬2æ­¥ä¸­è®°å½•çš„ U å€¼ï¼Œåˆ™å›åˆ°ç¬¬3æ­¥é‡æ–°è·å–å¿«ç…§ã€‚

        5. åœ¨ç¼“å†²çš„äº‹ä»¶ä¸­ï¼Œä¸¢å¼ƒæ‰€æœ‰ u å°äºç­‰äº å¿«ç…§ lastUpdateId çš„äº‹ä»¶ã€‚æ­¤æ—¶ï¼Œç¬¬ä¸€ä¸ªç¼“å†²äº‹ä»¶çš„ [U, u] èŒƒå›´åº”èƒ½åŒ…å«è¯¥ lastUpdateIdã€‚

        6. å°†ä½ çš„æœ¬åœ°è®¢å•ç°¿è®¾ç½®ä¸ºè¯¥å¿«ç…§ã€‚å…¶æ›´æ–°IDå³ä¸º lastUpdateIdã€‚

        7. å°†ä¸‹è¿°æ›´æ–°æµç¨‹ä¾æ¬¡åº”ç”¨äºæ‰€æœ‰ç¼“å†²äº‹ä»¶ï¼Œä»¥åŠä¹‹åæ”¶åˆ°çš„æ‰€æœ‰åç»­äº‹ä»¶ã€‚

    åº”ç”¨äº‹ä»¶åˆ°æœ¬åœ°è®¢å•ç°¿çš„æ›´æ–°æµç¨‹ï¼š

        1. åˆ¤æ–­æ›´æ–°äº‹ä»¶æ˜¯å¦å¯åº”ç”¨ï¼š

            å¦‚æœäº‹ä»¶çš„æœ€åæ›´æ–°ID (u) å°äº æœ¬åœ°è®¢å•ç°¿çš„å½“å‰æ›´æ–°IDï¼Œåˆ™å¿½ç•¥è¯¥äº‹ä»¶ã€‚

            å¦‚æœäº‹ä»¶çš„èµ·å§‹æ›´æ–°ID (U) å¤§äº æœ¬åœ°è®¢å•ç°¿å½“å‰æ›´æ–°ID åŠ  1ï¼Œè¯´æ˜ä½ å·²ä¸¢å¤±äº†ä¸€äº›äº‹ä»¶ã€‚å¿…é¡»ä¸¢å¼ƒæ•´ä¸ªæœ¬åœ°è®¢å•ç°¿ï¼Œå¹¶ä»å¤´å¼€å§‹é‡å¯æ•´ä¸ªæµç¨‹ã€‚

            é€šå¸¸ï¼Œä¸‹ä¸€ä¸ªäº‹ä»¶çš„ U ä¼šç­‰äºå‰ä¸€ä¸ªäº‹ä»¶çš„ u + 1ã€‚

        2. åº”ç”¨å˜æ›´ï¼š å¯¹äºäº‹ä»¶ä¸­ bids (b) å’Œ asks (a) é‡Œçš„æ¯ä¸ªä»·æ ¼æ¡£ä½ï¼š

            å¦‚æœè¯¥ä»·æ ¼æ¡£ä½ä¸å­˜åœ¨äºè®¢å•ç°¿ä¸­ï¼Œåˆ™ä»¥å…¶æ–°æ•°é‡æ’å…¥ã€‚

            å¦‚æœæ•°é‡ä¸ºé›¶ï¼Œåˆ™ä»è®¢å•ç°¿ä¸­ç§»é™¤è¯¥ä»·æ ¼æ¡£ä½ã€‚

        3. å°†è®¢å•ç°¿çš„æ›´æ–°IDè®¾ç½®ä¸ºå·²å¤„ç†äº‹ä»¶çš„æœ€åæ›´æ–°ID (u)ã€‚

    [!æ³¨æ„]
        ç”±äºä»APIè·å–çš„æ·±åº¦å¿«ç…§å¯¹ä»·æ ¼æ¡£ä½æ•°é‡æœ‰é™åˆ¶ï¼ˆæ¯è¾¹æœ€å¤š5000æ¡£ï¼‰ï¼Œå› æ­¤å¯¹äºåˆå§‹å¿«ç…§ä¹‹å¤–çš„æ¡£ä½ï¼Œé™¤éå®ƒä»¬å‘ç”Ÿå˜åŒ–ï¼Œå¦åˆ™ä½ å°†æ— æ³•è·çŸ¥å…¶æ•°é‡ã€‚
        åœ¨ä½¿ç”¨è¿™äº›æ¡£ä½çš„ä¿¡æ¯æ—¶è¯·åŠ¡å¿…å°å¿ƒï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½æ— æ³•åæ˜ è®¢å•ç°¿çš„å…¨è²Œã€‚ç„¶è€Œï¼Œå¯¹äºå¤§å¤šæ•°ä½¿ç”¨åœºæ™¯ï¼Œæ¯è¾¹çœ‹åˆ°5000æ¡£å·²è¶³ä»¥ç†è§£å¸‚åœºå¹¶è¿›è¡Œæœ‰æ•ˆäº¤æ˜“ã€‚
'''


# ---------------------------------------------------------------------------
# BinanceAdapter
#    * WS å…ˆå¯åŠ¨å¹¶ buffer æ›´æ–° -> ç„¶å REST snapshot -> åº”ç”¨ bufferï¼ˆBinance æ¨èæµç¨‹ï¼‰
#    * pending_updates ä¸¥æ ¼æŒ‰æ¥æ”¶é¡ºåºå¤„ç†å¹¶å¯»æ‰¾é“¾å¼èµ·ç‚¹ï¼šU <= lastUpdateId+1 <= u
#    * æä¾› fallback é™çº§æµç¨‹ï¼ˆä»…åœ¨ REST å®Œå…¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
#    * éé˜»å¡å›è°ƒè°ƒåº¦ï¼ˆé¿å…é˜»å¡ WS å¤„ç†ï¼‰
#    * pending buffer ä¸Šé™ï¼ˆé˜²æ­¢å†…å­˜æ— é™å¢é•¿ï¼‰
# ---------------------------------------------------------------------------

class BinanceAdapter(BaseAdapter):
    """Binance äº¤æ˜“æ‰€é€‚é…å™¨ - snapshot + buffering + pending åˆå¹¶çš„å®Œæ•´å®ç°"""

    # pending buffer æœ€å¤§é•¿åº¦ï¼ˆä¿æŠ¤å†…å­˜ï¼‰
    PENDING_MAX_LEN = 10000
    # å¦‚æœ pending è¶…è¿‡è¿™ä¸ªæ•°é‡ï¼Œè§¦å‘é‡æ‹‰ snapshot çš„é˜ˆå€¼ï¼ˆå¯ä»¥æ ¹æ®åœºæ™¯è°ƒæ•´ï¼‰
    PENDING_RESYNC_THRESHOLD = 5000

    def __init__(self, verification_enabled: bool = True, verification_interval: int = 1):
        super().__init__("binance", ExchangeType.BINANCE)
        self.ws_url = "wss://stream.binance.com:9443/ws"
        self.ws_url_1 = "wss://stream.binance.com:443"
        self.ws_url_market_data = "wss://data-stream.binance.vision"
        self.rest_base_url = "https://api.binance.com/api/v3"

        # è®¢å•ç°¿çŠ¶æ€ç®¡ç†
        self.orderbook_snapshots: Dict[str, OrderBook] = {}
        self.last_update_ids: Dict[str, int] = {}
        self.pending_updates: Dict[str, List[dict]] = {}      # ä¸¥æ ¼æŒ‰åºå­˜æ”¾æš‚æ— æ³•å¤„ç†çš„å®æ—¶å¢é‡æ›´æ–°çš„é˜Ÿåˆ—
        self.snapshot_initialized: Dict[str, bool] = {}       # å¸ƒå°”é”ã€‚Falseæ—¶æ‰€æœ‰æ›´æ–°è¿›â€œå¾…åŠæ¸…å•â€ï¼›Trueåæ›´æ–°å¯ç›´æ¥åº”ç”¨

        # äº¤æ˜“æ•°æ®ç®¡ç†
        self.last_trade: Dict[str, TradeTick] = {}
        self.recent_trades: Dict[str, Deque[TradeTick]] = defaultdict(lambda: deque(maxlen=100))

        # éªŒè¯æ§åˆ¶
        self._verification_enabled = verification_enabled
        self._verification_interval = verification_interval
        self._verification_tasks: Dict[str, asyncio.Task] = {}
        self._verification_stats: Dict[str, Dict] = defaultdict(lambda: {
            'total_verifications': 0,
            'passed_verifications': 0,
            'failed_verifications': 0,
            'last_verification_time': None,
            'last_verification_result': None,
        })

        # WebSocket connector (å‡è®¾å·²å®ç°)
        self.connector = WebSocketConnector(
            url=self.ws_url,
            on_message=self._handle_raw_message,
            on_error=self._handle_connection_error,
            ping_interval=30,
            timeout=10,
            name="binance"
        )

        # ç”¨ä»¥å­˜æ”¾ subscribe åæ­£åœ¨è¿›è¡Œ snapshot åˆå§‹åŒ–çš„ä»»åŠ¡ï¼Œé¿å…é‡å¤ init
        self._init_tasks: Dict[str, asyncio.Task] = {}

    # -----------------------
    # helper: buffer management
    # -----------------------
    def _ensure_symbol_structs(self, symbol: str):
        if symbol not in self.pending_updates:
            self.pending_updates[symbol] = []
        if symbol not in self.snapshot_initialized:
            self.snapshot_initialized[symbol] = False
        if symbol not in self.orderbook_snapshots:
            self.orderbook_snapshots[symbol] = OrderBook(
                bids=[], 
                asks=[], 
                server_timestamp=0,  # æ˜ç¡®è¡¨ç¤ºâ€œæœªçŸ¥â€
                receive_timestamp=0,  # æ˜ç¡®è¡¨ç¤ºâ€œæœªçŸ¥â€
                symbol=symbol)  
        if symbol not in self.last_trade:
            self.last_trade[symbol] = None
        if symbol not in self.recent_trades:
            # é»˜è®¤ä¿å­˜æœ€è¿‘100æ¡äº¤æ˜“è®°å½•
            self.recent_trades[symbol] = deque(maxlen=100)    
            
    def _reset_symbol_state(self, symbol: str):
        """æ¸…ç†æŒ‡å®šsymbolçš„æ‰€æœ‰çŠ¶æ€"""
        self.orderbook_snapshots.pop(symbol, None)
        self.last_update_ids.pop(symbol, None)
        if symbol in self.pending_updates:
            self.pending_updates[symbol] = []
        self.snapshot_initialized[symbol] = False 
        logger.debug(f"Reset state for symbol {symbol}")                 

    # -----------------------
    # snapshot init with buffering
    # -----------------------
    async def _init_snapshot_with_buffering(self, symbol: str) -> bool:
        """
        æ­£ç¡®çš„ snapshot åˆå§‹åŒ–æµç¨‹ï¼ˆä¸¥æ ¼éµå¾ª Binance å®˜æ–¹é¡ºåºï¼‰ï¼š
        1) WS å·²åœ¨è¿è¡Œå¹¶æŠŠæ‰€æœ‰æ›´æ–°ç¼“å†²åˆ° pending_updates[symbol]
        2) é€šè¿‡ REST è·å– snapshot(lastUpdateId)
        3) ä» pending ä¸­ä¸¢å¼ƒæ‰€æœ‰ u <= lastUpdateIdï¼ˆå·²åŒ…å«åœ¨snapshotï¼‰
        4) æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ»¡è¶³ U <= lastUpdateId+1 <= u çš„ buffered update ä½œä¸ºèµ·ç‚¹ï¼Œåº”ç”¨å®ƒå’Œä¹‹åèƒ½è¿ä¸Šçš„æ›´æ–°
        5) è‹¥æ— æ³•æ‰¾åˆ°é“¾å¼èµ·ç‚¹ï¼Œåˆ™å°è¯•æ¸…ç©º buffer æˆ–è€…è§¦å‘é‡æ‹‰ snapshotï¼ˆè§†å…·ä½“å®¹å¿ç­–ç•¥ï¼‰
        """
        symbol = symbol.upper()
        self._ensure_symbol_structs(symbol)

        try:
            # REST snapshot via RESTConnector context manager
            async with RESTConnector(base_url=self.rest_base_url, timeout=15, name=f"binance_{symbol}") as rest:
                snapshot = await rest.get_json(f"/depth?symbol={symbol}&limit=100")
        except Exception as e:
            logger.exception("snapshot REST failed for %s: %s", symbol, e)
            # do not immediately fallback to using first update â€” keep snapshot uninitialized
            self.snapshot_initialized[symbol] = False
            return False

        logger.info("Get snapshot for %s", symbol)
        # parse snapshot
        try:
            last_update_id = int(snapshot['lastUpdateId'])
        except Exception:
            logger.error("snapshot missing lastUpdateId for %s: %s", symbol, snapshot)
            self.snapshot_initialized[symbol] = False
            return False

        # build orderbook from snapshot
        bids = [OrderBookLevel(price=Decimal(b[0]), quantity=Decimal(b[1])) for b in snapshot.get('bids', [])]
        asks = [OrderBookLevel(price=Decimal(a[0]), quantity=Decimal(a[1])) for a in snapshot.get('asks', [])]
        bids.sort(key=lambda x: x.price, reverse=True)
        asks.sort(key=lambda x: x.price)
        bids = bids[:20]
        asks = asks[:20]

        receive_ts = int(datetime.now(timezone.utc).timestamp() * 1000)
        orderbook = OrderBook(
            bids=bids,
            asks=asks,
            server_timestamp=last_update_id,   # ä½¿ç”¨ last_update_id ä½œä¸º server_timestamp çš„å ä½ç¬¦
            receive_timestamp=receive_ts,      # æœ¬åœ°æ¥æ”¶æ—¶é—´
            symbol=symbol,
            last_update_id=last_update_id
        )

        # store snapshot
        self.orderbook_snapshots[symbol] = orderbook
        self.last_update_ids[symbol] = last_update_id
        self.snapshot_initialized[symbol] = True
        logger.info("Initialized snapshot for %s lastUpdateId=%d (pending buffer len=%d)",
                    symbol, last_update_id, len(self.pending_updates.get(symbol, [])))

        # process buffered updates
        buffered = list(self.pending_updates.get(symbol, []))  # shallow copy preserving order
        # drop any buffered update with u <= last_update_id (already included)
        filtered = [u for u in buffered if (u.get('u') or 0) > last_update_id]

        # æ¸…ç©ºpendingé˜Ÿåˆ—ï¼ˆæ— è®ºæ˜¯å¦åº”ç”¨æ›´æ–°ï¼‰
        self.pending_updates[symbol] = []

        applied_any = False
        expected = last_update_id + 1

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ»¡è¶³ U <= expected <= u çš„ update
        for upd in filtered:
            U = upd.get('U')
            u = upd.get('u')
            logger.debug(f"applying {upd} to {symbol}, expected = {expected}, U = {U}, u = {u}")
            if U is None or u is None:
                # å¦‚æœå­—æ®µç¼ºå¤±ï¼Œè·³è¿‡ï¼›ä½†ä¿ç•™åœ¨ buffer é‡Œä»¥ä¾›åç»­åˆ¤æ–­æˆ–ç›´æ¥ä¸¢å¼ƒ
                continue
            if U <= expected <= u:
                # apply this update
                try:
                    self._apply_orderbook_update(symbol, upd, False)
                    self.last_update_ids[symbol] = int(u)
                    expected = int(u) + 1
                    applied_any = True
                    logger.debug(f"applied {upd} to {symbol}, expected = {expected}, U = {U}, u = {u}")
                except Exception:
                    logger.exception("Failed to apply chained update during init for %s", symbol)
                break

        if applied_any:
            # apply remaining updates in order if they can be chained
            remaining = [u for u in filtered if (u.get('u') or 0) > self.last_update_ids[symbol]]
            for upd in remaining:
                curU = upd.get('U')
                curu = upd.get('u')
                if curU is None or curu is None:
                    continue
                if curU <= self.last_update_ids[symbol] + 1 <= curu:
                    try:
                        self._apply_orderbook_update(symbol, upd, False)
                        self.last_update_ids[symbol] = int(curu)
                    except Exception:
                        logger.exception("Failed to apply subsequent buffered update for %s", symbol)
                else:
                    # æ— æ³•ç»§ç»­é“¾å¼è¿æ¥ -> æŠŠå°šæœªåº”ç”¨çš„ remaining æ”¾å› pendingï¼ˆä¿ç•™æ¥æ”¶é¡ºåºï¼‰
                    idx = remaining.index(upd)
                    self.pending_updates[symbol] = remaining[idx:]
                    logger.warning("Could not chain buffered updates for %s, leaving %d in pending", symbol, len(self.pending_updates[symbol]))
                    break
        else:
            if len(filtered) == 0:
                # æƒ…å†µ1ï¼šæ‰€æœ‰ç¼“å†²æ›´æ–°éƒ½æ˜¯æ—§æ•°æ®ï¼ˆu <= last_update_idï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼
                logger.info(
                    f"All buffered updates for {symbol} are already included in snapshot. "
                    f"Buffered={len(buffered)}, last_update_id={last_update_id}. "
                    f"This is normal - waiting for new updates."
                )
                # å·²ç»æ¸…ç©ºäº†pendingï¼Œä¸éœ€è¦é¢å¤–æ“ä½œ
            else:
                # æƒ…å†µ2ï¼šæœ‰æ–°çš„æ›´æ–°ï¼ˆu > last_update_idï¼‰ï¼Œä½†æ— æ³•è¿æ¥
                # åˆšæ€§æ­£ç¡®ï¼šå¦‚æœæ‰¾ä¸åˆ°é“¾å¼èµ·ç‚¹ï¼Œè¯´æ˜ç¼“å†²åŒºä¸å¿«ç…§æ— æ³•å¯¹é½
                # è¿™æ˜¯ä¸¥é‡çš„æ•°æ®ä¸ä¸€è‡´ï¼Œéœ€è¦æ ‡è®°çŠ¶æ€æ— æ•ˆ
                logger.error(
                    f"Rigid correctness: Cannot chain buffered updates for {symbol}. "
                    f"Buffered={len(buffered)}, last_update_id={last_update_id}. "
                    f"Marking snapshot as uninitialized."
                )
            
                # æ¸…ç†çŠ¶æ€ï¼Œä¿æŒä¸€è‡´æ€§
                self._reset_symbol_state(symbol)
            
                return False  
        
        return True

    # -----------------------
    # apply update -> snapshot merge
    # -----------------------
    def _apply_orderbook_update(self, symbol: str, update_data: dict, notify: bool = True):
        """æŠŠå¢é‡æ›´æ–°åº”ç”¨åˆ°æœ¬åœ° snapshotï¼ˆç®€åŒ–çš„ add/remove æ¨¡å‹ï¼‰"""
        try:
            current_orderbook = self.orderbook_snapshots.get(symbol)
            if current_orderbook is None:
                # è¿™ä¸åº”è¯¥å‘ç”Ÿï¼è®°å½•ä¸¥é‡é”™è¯¯ï¼Œå¹¶è§¦å‘ç´§æ€¥æ¢å¤æˆ–åœæ­¢å¤„ç†ã€‚
                logger.critical(
                    f"CRITICAL: Attempted to apply update for {symbol} but orderbook snapshot is None. "
                    f"This indicates a serious state management bug. Update data: {update_data}"
                )
                # æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚é”™è¯¯å¤„ç†é€»è¾‘æ¥ç®¡ï¼ˆå¯èƒ½è§¦å‘é‡è¿/é‡å¯ï¼‰
                raise ValueError(f"Orderbook snapshot for {symbol} is missing. State inconsistent.")

            # shallow copy lists
            new_bids = list(current_orderbook.bids) if current_orderbook.bids else []
            new_asks = list(current_orderbook.asks) if current_orderbook.asks else []

            # bids æ›´æ–°
            for price_str, quantity_str in update_data.get('b', []):
                price = Decimal(price_str)
                quantity = Decimal(quantity_str)
                # remove any existing at that price
                new_bids = [b for b in new_bids if b.price != price]
                if quantity > 0:
                    new_bids.append(OrderBookLevel(price=price, quantity=quantity))

            # asks æ›´æ–°
            for price_str, quantity_str in update_data.get('a', []):
                price = Decimal(price_str)
                quantity = Decimal(quantity_str)
                new_asks = [a for a in new_asks if a.price != price]
                if quantity > 0:
                    new_asks.append(OrderBookLevel(price=price, quantity=quantity))

            # æ’åºä¸è£å‰ª
            new_bids.sort(key=lambda x: x.price, reverse=True)
            new_asks.sort(key=lambda x: x.price)
            new_bids = new_bids[:20]
            new_asks = new_asks[:20]

            # ç¡®å®š server_timestamp
            server_ts = update_data.get('E')
            if server_ts is None:
                logger.warning(f"No 'E' field for {symbol} in {update_data}")

            # ç¡®å®š last_update_id
            last_update_id = update_data.get('u')
            if last_update_id is None:
                logger.warning(f"No 'u' field for {symbol} in {update_data}")

            receive_ts = int(datetime.now(timezone.utc).timestamp() * 1000)

            updated = OrderBook(
                bids=new_bids,
                asks=new_asks,
                server_timestamp=int(server_ts),   # æ¥è‡ªæœåŠ¡å™¨çš„äº‹ä»¶æ—¶é—´
                receive_timestamp=receive_ts,      # æœ¬åœ°æ¥æ”¶æ—¶é—´
                symbol=symbol,
                last_update_id=last_update_id  # ä½¿ç”¨æ›´æ–°æ¶ˆæ¯ä¸­çš„uå­—æ®µ
            )    

            self.orderbook_snapshots[symbol] = updated
            logger.debug("Applied orderbook update for %s: bids=%d asks=%d", symbol, len(new_bids), len(new_asks))

            # å‘å¸ƒ MarketData ç»™ä¸‹æ¸¸ï¼ˆéé˜»å¡ï¼‰
            if notify: # åªæœ‰å½“ notify=True æ—¶æ‰è§¦å‘å›è°ƒ
                # åˆ›å»ºå¸‚åœºæ•°æ®å¹¶è§¦å‘å›è°ƒ
                market_data = self._create_market_data(
                    symbol=symbol,
                    exchange=ExchangeType.BINANCE,
                    market_type=MarketType.SPOT,
                    external_timestamp=receive_ts,
                    orderbook=updated
                )
                
                if market_data:
                    logger.debug(f"Callback for {market_data}")
                    self._notify_callbacks(market_data)

        except Exception as e:
            logger.exception("Error applying orderbook update for %s: %s", symbol, e)
            raise    

    # -----------------------
    # connect / subscribe
    # -----------------------
    async def connect(self) -> bool:
        """å»ºç«‹ WS è¿æ¥ï¼ˆéé˜»å¡ï¼‰"""
        try:
            success = await self.connector.connect()
            self.is_connected = success
            logger.info("Binance WS connected=%s", success)
            self._record_connection_event(success)
            return success
        except Exception as e:
            logger.exception("Binance connection failed: %s", e)
            self._record_connection_event(False)
            self.is_connected = False
            return False

    async def disconnect(self):
        try:
            await self.connector.disconnect()
        finally:
            self.is_connected = False

    async def _do_subscribe(self, symbols: List[str]):
        """
        è®¢é˜…æ·±åº¦+tradeæµï¼Œé‡è¦æµç¨‹ï¼š
         1) å…ˆç¡®ä¿ WS å·² connect å¹¶å¼€å§‹æ¥æ”¶ï¼ˆé»˜è®¤ connector å·²è¿æ¥ï¼‰
         2) å¯¹æ¯ä¸ª symbol åˆå§‹åŒ– pending ç»“æ„
         3) å‘èµ·è®¢é˜…
         4) å¹¶è¡Œè§¦å‘ _init_snapshot_with_buffering(symbol)ï¼ˆREST snapshotï¼‰ï¼Œè®© WS åœ¨æ­¤æœŸé—´æŒç»­ buffer
        """
        if not self.is_connected:
            logger.warning("Not connected to Binance")
            return

        streams = []
        for symbol in symbols:
            symbol_lower = symbol.lower()
            streams.extend([f"{symbol_lower}@depth@100ms", f"{symbol_lower}@trade"])
            self._ensure_symbol_structs(symbol)

        subscribe_msg = {"method": "SUBSCRIBE", "params": streams, "id": 1}
        await self.connector.send_json(subscribe_msg)
        logger.info("Subscribed to %s on Binanceï¼Œ msg is: %s", symbols, subscribe_msg)

        # è®°å½•æˆåŠŸå’Œå¤±è´¥çš„symbol
        success_symbols = []
        fail_symbols = []

        # å¹¶è¡Œåˆå§‹åŒ– snapshotï¼ˆå¸¦ buffering å¤„ç†ï¼‰
        tasks = []
        for symbol in symbols:
            # é˜²æ­¢é‡å¤åˆ›å»ºå¤šä¸ª init ä»»åŠ¡
            if symbol in self._init_tasks and not self._init_tasks[symbol].done():
                continue
            t = asyncio.create_task(self._init_snapshot_with_buffering(symbol))
            self._init_tasks[symbol] = t
            tasks.append((symbol, t))
        
        if tasks:
            # ä½¿ç”¨gatherå¹¶è¡Œç­‰å¾…ï¼Œä½†æ•è·æ¯ä¸ªä»»åŠ¡çš„ç»“æœ
            results = await asyncio.gather(
                *(task for _, task in tasks),
                return_exceptions=True
            )
            
            # å¤„ç†æ¯ä¸ªä»»åŠ¡çš„ç»“æœ
            for (symbol, _), result in zip(tasks, results):
                if isinstance(result, Exception):
                    logger.error(f"{symbol}: Initialization exception: {result}")
                    fail_symbols.append(symbol)
                elif result:
                    logger.info(f"{symbol}: Initialization successful")
                    success_symbols.append(symbol)

                    try:
                        if self._verification_enabled:
                            # å¯åŠ¨éªŒè¯ä»»åŠ¡ï¼Œæ¯ç§’éªŒè¯ä¸€æ¬¡ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´é—´éš”ï¼‰
                            self.start_verification(symbol, interval_seconds=1)
                    except Exception as e:
                        logger.error(f"Failed to start verification for {symbol}: {e}Error messageClick to retry")
                else:
                    logger.error(f"{symbol}: Initialization failed")
                    fail_symbols.append(symbol)
                
                # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                if symbol in self._init_tasks:
                    task = self._init_tasks[symbol]
                    if task.done():
                        self._init_tasks.pop(symbol, None)
        
        # æ€»ç»“æ—¥å¿—
        if success_symbols:
            logger.info(f"Successfully initialized: {success_symbols}")
        if fail_symbols:
            logger.error(f"Failed to initialize: {fail_symbols}")

    async def _do_unsubscribe(self, symbols: List[str]):
        if not self.is_connected:
            return
        streams = []
        for symbol in symbols:
            symbol_lower = symbol.lower()
            streams.extend([f"{symbol_lower}@depth@100ms", f"{symbol_lower}@trade"])
        unsubscribe_msg = {"method": "UNSUBSCRIBE", "params": streams, "id": 1}
        await self.connector.send_json(unsubscribe_msg)
        logger.info("Unsubscribed from %s on Binance", symbols)
        

    # -----------------------
    # raw message handlerï¼ˆWS å›è°ƒå…¥å£ï¼‰
    # -----------------------
    def _handle_raw_message(self, raw_data: dict):
        """
        on_message å…¥å£ã€‚raw_data å¯èƒ½æ˜¯ stream åŒ…è£…ï¼ˆ{stream, data}ï¼‰æˆ– event æ ¼å¼ï¼ˆ{e: 'depthUpdate', ...}ï¼‰
        """
        try:
            # stream åŒ…è£…
            if 'stream' in raw_data:
                stream = raw_data['stream']
                if '@depth' in stream:
                    # depth updates are in raw_data['data']
                    self._handle_orderbook_update(raw_data)
                elif '@trade' in stream:
                    self._handle_trade(raw_data)
                else:
                    logger.debug("Unknown stream message: %s", stream)
            # event æ ¼å¼
            elif 'e' in raw_data:
                event_type = raw_data['e']
                if event_type == 'depthUpdate':
                    self._handle_orderbook_update(raw_data)
                elif event_type == 'trade':
                    self._handle_trade(raw_data)
                else:
                    logger.debug("Unhandled event type: %s", event_type)
            elif 'result' in raw_data:
                event_type = raw_data['result']  
                if event_type is None:
                    pass
                else:
                    logger.info("Unrecognized message shape from Binance WS: %s", raw_data)
            else:
                logger.info("Unrecognized message shape from Binance WS: %s", raw_data)
        except Exception as e:
            logger.exception("Error handling raw message: %s", e)

    # -----------------------
    # orderbook update core
    # -----------------------
    def _handle_orderbook_update(self, data: dict):
        """å¤„ç†è®¢å•ç°¿å¢é‡æ›´æ–°ï¼ˆåˆšæ€§æ­£ç¡®ç­–ç•¥ï¼šä»»ä½•ä¸è¿ç»­éƒ½è§¦å‘é‡åŒæ­¥ï¼‰"""
        try:
            if 'stream' in data:
                symbol = data['stream'].split('@')[0].upper()
                update_data = data['data']
            else:
                symbol = data.get('s') or data.get('symbol')
                update_data = data

            if not symbol:
                logger.warning("Orderbook update missing symbol: %s", data)
                return

            self._ensure_symbol_structs(symbol)

            # å¦‚æœ snapshot æœªåˆå§‹åŒ–ï¼Œç¼“å†²æ›´æ–°
            if not self.snapshot_initialized.get(symbol, False):
                self._buffer_incoming_update(symbol, update_data)
                return

            # å·²åˆå§‹åŒ–çš„å¤„ç†é€»è¾‘ï¼ˆä¸¥æ ¼æ£€æŸ¥è¿ç»­æ€§ï¼‰
            current_U = update_data.get('U')
            current_u = update_data.get('u')
            last_update_id = self.last_update_ids.get(symbol)

            # 1. ä¸¢å¼ƒæ—§æ›´æ–°
            if last_update_id is not None and current_u is not None and int(current_u) <= int(last_update_id):
                logger.debug("Dropping old update for %s: u=%s <= last=%s", symbol, current_u, last_update_id)
                return

            # 2. ä¸¥æ ¼è¿ç»­æ€§æ£€æŸ¥
            if last_update_id is not None and current_U is not None and current_u is not None:
                expected = int(last_update_id) + 1
                
                if int(current_U) <= expected <= int(current_u):
                    # å®Œç¾è¿ç»­ï¼šåº”ç”¨æ›´æ–°
                    self._apply_orderbook_update(symbol, update_data)
                    self.last_update_ids[symbol] = int(current_u)
                    return
                else:
                    # ğŸ”¥ ä»»ä½•ä¸è¿ç»­æ€§éƒ½è§¦å‘é‡æ–°åŒæ­¥
                    # è¿™åŒ…æ‹¬ä¸¤ç§æƒ…å†µï¼š
                    # 1. current_U > expectedï¼šæœ‰æ˜æ˜¾é—æ¼
                    # 2. current_U <= expected ä½† expected > current_uï¼šUè¾ƒå°ä½†uä¸å¤Ÿå¤§ï¼ˆå®é™…ä¸Šä¸åº”å‘ç”Ÿï¼‰
                    logger.warning(
                        f"Rigid correctness triggered: gap for {symbol}. "
                        f"last_update_id={last_update_id}, expected={expected}, "
                        f"received U={current_U}, u={current_u}. Triggering re-init."
                    )
                    asyncio.create_task(self._retry_snapshot_initialization(symbol))
                    return
            else:
                # 3. ç¼ºå°‘å¿…è¦å­—æ®µï¼šè§†ä¸ºé”™è¯¯çŠ¶æ€ï¼Œè§¦å‘é‡æ–°åŒæ­¥
                logger.error(
                    f"Missing required fields for {symbol}: last_update_id={last_update_id}, "
                    f"U={current_U}, u={current_u}. raw data={data}. Triggering re-init."
                )
                asyncio.create_task(self._retry_snapshot_initialization(symbol))
                return

        except Exception as e:
            logger.exception("Error processing Binance orderbook update: %s", e)          

    def _buffer_incoming_update(self, symbol: str, update_data: dict):
        """æŠŠæ¥æ”¶åˆ°çš„ WS å¢é‡æ›´æ–°æŒ‰æ¥æ”¶é¡ºåºè¿½åŠ è¿› pending buffer"""
        self._ensure_symbol_structs(symbol)
        buf = self.pending_updates[symbol]
        buf.append(update_data)

        # é˜²æŠ¤ï¼šé™åˆ¶ buffer é•¿åº¦
        if len(buf) > self.PENDING_MAX_LEN:
            # ä¿ç•™æœ€æ–°éƒ¨åˆ†ï¼ˆä¸¢å¼ƒæ—§çš„ä¸€åŠï¼‰
            keep = buf[-(self.PENDING_MAX_LEN // 2):]
            self.pending_updates[symbol] = keep
            logger.warning(f"pending_updates for {symbol} exceeded max len; trimmed to {len(keep)}")

        # å¦‚æœ buffer æåº¦è†¨èƒ€ï¼Œå»ºè®®é‡æ‹‰ snapshotï¼ˆå¼‚æ­¥è§¦å‘ï¼‰
        if len(self.pending_updates[symbol]) > self.PENDING_RESYNC_THRESHOLD:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰é‡è¯•ä»»åŠ¡åœ¨è¿è¡Œ
            if symbol in self._init_tasks and not self._init_tasks[symbol].done():
                logger.debug(f"Retry already in progress for {symbol}, skipping")
                return
                
            logger.warning(f"pending_updates for {symbol} reached resync threshold ({len(self.pending_updates[symbol])}), scheduling snapshot re-init")
            task = asyncio.create_task(self._retry_snapshot_initialization(symbol))
            self._init_tasks[symbol] = task     


    # -----------------------
    # trade
    # -----------------------
    def _handle_trade(self, data: dict) -> None:
        """
        å¤„ç†äº¤æ˜“æ¶ˆæ¯
        Binance trade æ¶ˆæ¯æ ¼å¼:
        {
            "e": "trade",        // äº‹ä»¶ç±»å‹
            "E": 123456789,      // äº‹ä»¶æ—¶é—´ (æœåŠ¡å™¨æ—¶é—´)
            "s": "BTCUSDT",      // äº¤æ˜“å¯¹
            "t": 12345,          // äº¤æ˜“ID
            "p": "0.001",        // ä»·æ ¼
            "q": "100",          // æ•°é‡
            "b": 88,             // ä¹°æ–¹è®¢å•ID
            "a": 50,             // å–æ–¹è®¢å•ID
            "T": 123456785,      // äº¤æ˜“æ—¶é—´æˆ³
            "m": true,           // ä¹°æ–¹æ˜¯å¦æ˜¯åšå¸‚æ–¹ï¼Ÿå¦‚æœæ˜¯trueï¼Œåˆ™ä¹°æ–¹æ˜¯å¸‚ä»·å•ï¼Œå–æ–¹æ˜¯æŒ‚å•æ–¹ï¼Œå³ä¸»åŠ¨å–å‡º
            "M": true            // å¿½ç•¥
        }
        
        æ³¨æ„ï¼šmå­—æ®µè¡¨ç¤ºä¹°æ–¹æ˜¯å¦æ˜¯åšå¸‚æ–¹
        - m=True: ä¹°æ–¹æ˜¯å¸‚ä»·å•ï¼Œå–æ–¹æ˜¯æŒ‚å•æ–¹ -> ä¸»åŠ¨å–å‡º (SELL)
        - m=False: ä¹°æ–¹æ˜¯æŒ‚å•æ–¹ï¼Œå–æ–¹æ˜¯å¸‚ä»·å• -> ä¸»åŠ¨ä¹°å…¥ (BUY)
        """
        try:
            # ä»dataä¸­æå–äº¤æ˜“æ•°æ®
            if 'stream' in data:
                # streamæ ¼å¼: btcusdt@trade
                stream_data = data['data']
                symbol = stream_data.get('s', '').upper()
                trade_data = stream_data
            else:
                symbol = data.get('s', '').upper()
                trade_data = data
            
            if not symbol:
                logger.warning("Trade message missing symbol: %s", data)
                return
            
            # è·å–ä»·æ ¼å’Œæ•°é‡
            price_str = trade_data.get('p')
            quantity_str = trade_data.get('q')
            
            if not price_str or not quantity_str:
                logger.warning("Trade message missing price or quantity: %s", trade_data)
                return
            
            # è§£æäº¤æ˜“æ–¹å‘
            # m=True: ä¹°æ–¹æ˜¯å¸‚ä»·å• -> ä¸»åŠ¨å–å‡º (SELL)
            # m=False: ä¹°æ–¹æ˜¯æŒ‚å•æ–¹ -> ä¸»åŠ¨ä¹°å…¥ (BUY)
            is_market_maker = trade_data.get('m', False)
            side = "SELL" if is_market_maker else "BUY"
            
            # è·å–æ—¶é—´æˆ³
            # ä¼˜å…ˆä½¿ç”¨äº¤æ˜“æ—¶é—´æˆ³(T)ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨äº‹ä»¶æ—¶é—´æˆ³(E)
            trade_time = trade_data.get('T', trade_data.get('E'))
            if not trade_time:
                logger.warning("Trade message missing timestamp: %s", trade_data)
                return
            
            # åˆ›å»ºTradeTickå¯¹è±¡
            trade_tick = TradeTick(
                symbol=symbol,
                trade_id=str(trade_data.get('t', '')),
                price=Decimal(price_str),
                size=Decimal(quantity_str),
                side=side,
                server_timestamp=int(trade_time),
                receive_timestamp=int(datetime.now(timezone.utc).timestamp() * 1000),
                exchange=ExchangeType.BINANCE
            )
            
            # æ›´æ–°last_trade
            self.last_trade[symbol] = trade_tick
            
            # æ·»åŠ åˆ°recent_trades
            if symbol in self.recent_trades:
                self.recent_trades[symbol].append(trade_tick)
            
            # åˆ›å»ºå¸‚åœºæ•°æ®å¹¶è§¦å‘å›è°ƒ
            market_data = self._create_market_data(
                symbol=symbol,
                exchange=ExchangeType.BINANCE,
                last_trade=trade_tick,
                external_timestamp=datetime.fromtimestamp(trade_time/1000, timezone.utc)
            )
            
            if market_data:
                logger.debug(f"Callback for {market_data}")
                self._notify_callbacks(market_data)
            
            
            logger.debug("Processed trade for %s: %s %s @ %s", 
                        symbol, side, quantity_str, price_str)
            
        except Exception as e:
            logger.exception("Error processing trade message: %s", e) 


    def _handle_connection_error(self, error: Exception):
        logger.error("Binance WebSocket connection error: %s", error)
        self.is_connected = False
        # å¼‚æ­¥é‡è¿
        asyncio.create_task(self._attempt_reconnect())

    async def _attempt_reconnect(self):
        logger.info("Attempting to reconnect to Binance WS...")
        await asyncio.sleep(2)
        try:
            success = await self.connect()
            if success and self.subscribed_symbols:
                await self.subscribe(list(self.subscribed_symbols))
        except Exception:
            logger.exception("Reconnection attempt failed")
    

    async def _retry_snapshot_initialization(self, symbol: str) -> bool:
        """é‡è¯•å¿«ç…§åˆå§‹åŒ–ï¼ˆåŒæ­¥é‡è¯•ï¼‰"""
        # é˜²æ­¢å¹¶å‘é‡è¯•
        if symbol in self._init_tasks and not self._init_tasks[symbol].done():
            logger.debug(f"Already retrying for {symbol}")
            return False
        
        logger.info(f"Starting snapshot re-init for {symbol}")
        
        # åŒæ­¥é‡è¯•ï¼Œæœ€å¤š3æ¬¡
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # é‡ç½®çŠ¶æ€
                self._reset_symbol_state(symbol)
                
                # ç›´æ¥è°ƒç”¨åˆå§‹åŒ–ï¼ˆåŒæ­¥ç­‰å¾…ï¼‰
                success = await self._init_snapshot_with_buffering(symbol)
                
                if success:
                    logger.info(f"Retry {attempt+1} successful for {symbol}")
                    # é‡è¯•æˆåŠŸï¼Œæ¸…ç†ä»»åŠ¡å¼•ç”¨
                    self._init_tasks.pop(symbol, None)
                    return True
                else:
                    logger.warning(f"Retry {attempt+1} failed for {symbol}")
                    
            except Exception as e:
                logger.warning(f"Retry {attempt+1} exception for {symbol}: {e}")
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡é‡è¯•ï¼Œç­‰å¾…åç»§ç»­
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        logger.error(f"All {max_retries} retries failed for {symbol}")
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œæ¸…ç†ä»»åŠ¡å¼•ç”¨
        self._init_tasks.pop(symbol, None)
        return False
    

    def normalize_data(self, raw_data: dict) -> Optional[MarketData]:
        """ä¿ç•™ç”¨äºå…¼å®¹æ¥å£çš„å ä½æ–¹æ³•"""
        return None


    # -----------------------
    # ç›‘æ§æ–¹æ³•
    # -----------------------
    def get_connection_status(self) -> dict:
        base_status = super().get_connection_status()
        connector_info = {}
        try:
            connector_info = self.connector.get_connection_info()
        except Exception:
            connector_info = {"info": "n/a"}
        return {
            **base_status,
            "connector_info": connector_info,
            "subscribed_symbols": list(self.subscribed_symbols),
            "snapshot_initialized": dict(self.snapshot_initialized)
        }


    def get_symbol_status(self, symbol: str) -> str:
        """è·å–symbolçš„å½“å‰çŠ¶æ€"""
        symbol = symbol.upper()
        
        if symbol not in self.pending_updates:
            return "unsubscribed"
        
        if self.snapshot_initialized.get(symbol, False):
            return "ready"
        
        if symbol in self._init_tasks:
            task = self._init_tasks[symbol]
            if task.done():
                try:
                    if task.result():
                        return "ready"  # ä»»åŠ¡æˆåŠŸï¼Œåº”è¯¥å·²ç»è¢«æ ‡è®°ä¸ºready
                    else:
                        return "failed"
                except Exception:
                    return "failed"
            else:
                return "initializing"
        
        return "pending"  # å·²è®¢é˜…ä½†æœªå¼€å§‹åˆå§‹åŒ–
    
    async def verify_orderbook_snapshot(self, symbol: str, tolerance: float = 0.001) -> Tuple[bool, Dict]:
        """
        ç²¾å‡†éªŒè¯è®¢å•ç°¿æ•°æ®æ­£ç¡®æ€§
        
        éªŒè¯ç­–ç•¥ï¼š
        1. æ£€æŸ¥æ›´æ–°IDåºåˆ—çš„è¿ç»­æ€§
        2. éªŒè¯æœ¬åœ°æ•°æ®åŒ…å«å¿«ç…§æ›´æ–°IDä¹‹åçš„æ‰€æœ‰æ›´æ–°
        3. ä½¿ç”¨REST APIçš„æ·±åº¦æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯
        
        Args:
            symbol: äº¤æ˜“å¯¹
            tolerance: å…è®¸çš„æ•°é‡è¯¯å·®ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤0.1%ï¼‰
            
        Returns:
            (æ˜¯å¦ä¸€è‡´, å·®å¼‚è¯¦æƒ…)
        """
        symbol = symbol.upper()
        
        try:
            # 1. è·å–REST APIå¿«ç…§å’Œæ·±åº¦
            async with RESTConnector(base_url=self.rest_base_url, timeout=10, name=f"binance_verify_{symbol}") as rest:
                snapshot = await rest.get_json(f"/depth?symbol={symbol}&limit=100")
                # åŒæ—¶è·å–æœ€æ–°æˆäº¤ä½œä¸ºå‚è€ƒ
                trades = await rest.get_json(f"/trades?symbol={symbol}&limit=1")
            
            snapshot_last_update_id = int(snapshot['lastUpdateId'])
            local_last_update_id = self.last_update_ids.get(symbol, 0)
            logger.info(f" è®¢å•ç°¿éªŒè¯: {symbol} (æœ¬åœ°æ›´æ–°ID: {local_last_update_id}, å¿«ç…§æ›´æ–°ID: {snapshot_last_update_id})")
            
            # 2. è·å–æœ¬åœ°è®¢å•ç°¿
            local_ob = self.orderbook_snapshots.get(symbol)
            if not local_ob:
                # æ›´æ–°ç»Ÿè®¡
                self._update_verification_stats(symbol, False, {'reason': 'local_orderbook_missing'})
                return False, {'reason': 'local_orderbook_missing'}
            
            # 3. æ£€æŸ¥æ›´æ–°IDçš„æ­£ç¡®æ€§ï¼ˆæ ¸å¿ƒéªŒè¯ï¼‰
            # æœ¬åœ°æ›´æ–°IDåº”è¯¥ >= å¿«ç…§æ›´æ–°IDï¼ˆå› ä¸ºæˆ‘ä»¬å¤„ç†äº†å¿«ç…§ä¹‹åçš„æ›´æ–°ï¼‰
            update_id_info = {
                'snapshot_update_id': snapshot_last_update_id,
                'local_update_id': local_last_update_id,
                'update_id_diff': local_last_update_id - snapshot_last_update_id
            }
            
            # å…³é”®éªŒè¯ç‚¹1ï¼šæœ¬åœ°åº”è¯¥åŒ…å«å¿«ç…§ä¹‹åçš„æ‰€æœ‰æ›´æ–°
            if local_last_update_id < snapshot_last_update_id:
                # æœ¬åœ°ç¼ºå°‘å¿«ç…§ä¹‹åçš„æ›´æ–°ï¼Œè¿™æ˜¯ä¸¥é‡é—®é¢˜
                return False, {
                    'reason': 'missing_updates_after_snapshot',
                    'message': f'æœ¬åœ°æ›´æ–°ID({local_last_update_id})å°äºå¿«ç…§æ›´æ–°ID({snapshot_last_update_id})ï¼Œç¼ºå°‘{snapshot_last_update_id - local_last_update_id}ä¸ªæ›´æ–°',
                    **update_id_info
                }
            
            # 4. æ·±åº¦äº¤å‰éªŒè¯ï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹æ³•ï¼‰
            snapshot_bids = {Decimal(b[0]): Decimal(b[1]) for b in snapshot.get('bids', [])}
            snapshot_asks = {Decimal(a[0]): Decimal(a[1]) for a in snapshot.get('asks', [])}
            
            # 5. è·å–æœ¬åœ°è®¢å•ç°¿çš„å‰Næ¡£ï¼ˆæ·±åº¦100ï¼‰
            local_bids = {}
            local_asks = {}
            
            for bid in local_ob.bids[:100]:
                local_bids[bid.price] = bid.quantity
            for ask in local_ob.asks[:100]:
                local_asks[ask.price] = ask.quantity

            logger.debug(f" è®¢å•ç°¿éªŒè¯: {symbol} (æœ¬åœ°bids: {local_bids}, å¿«ç…§bids: {snapshot_bids})")    
            logger.debug(f" è®¢å•ç°¿éªŒè¯: {symbol} (æœ¬åœ°asks: {local_asks}, å¿«ç…§asks: {snapshot_asks})")    
            
            # æ£€æŸ¥å·®å¼‚
            differences = []
            warnings = []
            critical_issues = []
            
            # å…³é”®éªŒè¯ç‚¹2ï¼š éªŒè¯ä¹°å–ç›˜äº¤å‰ï¼ˆåŸºæœ¬è§„åˆ™ï¼‰
            if local_ob.bids and local_ob.asks:
                best_bid = local_ob.bids[0].price
                best_ask = local_ob.asks[0].price
                if best_bid >= best_ask:
                    critical_issues.append(f"ä¹°å–ç›˜äº¤å‰: æœ€ä½³ä¹°ä»· {best_bid} >= æœ€ä½³å–ä»· {best_ask}")
            
            # å…³é”®éªŒè¯ç‚¹3ï¼š éªŒè¯ä»·æ ¼å•è°ƒæ€§
            for i in range(len(local_ob.bids) - 1):
                if local_ob.bids[i].price <= local_ob.bids[i + 1].price:
                    critical_issues.append(f"ä¹°ç›˜ä»·æ ¼éå•è°ƒé€’å‡: {local_ob.bids[i].price} <= {local_ob.bids[i + 1].price}")
                    break
            
            for i in range(len(local_ob.asks) - 1):
                if local_ob.asks[i].price >= local_ob.asks[i + 1].price:
                    critical_issues.append(f"å–ç›˜ä»·æ ¼éå•è°ƒé€’å¢: {local_ob.asks[i].price} >= {local_ob.asks[i + 1].price}")
                    break
            
            # 6. ä¸å¿«ç…§çš„ç²¾ç¡®æ¯”è¾ƒï¼ˆä½¿ç”¨Binanceçš„å¢é‡æ›´æ–°é€»è¾‘ï¼‰
            # Binanceçš„æ›´æ–°æœºåˆ¶ä¿è¯ï¼šå¦‚æœæˆ‘ä»¬çš„æ›´æ–°ID >= å¿«ç…§æ›´æ–°IDï¼Œå¹¶ä¸”æ­£ç¡®å¤„ç†äº†æ‰€æœ‰æ›´æ–°ï¼Œ
            # é‚£ä¹ˆæœ¬åœ°è®¢å•ç°¿åº”è¯¥æ˜¯æ­£ç¡®çš„ã€‚ä½†æˆ‘ä»¬å¯ä»¥éªŒè¯ä¸€äº›å…³é”®ç‚¹ï¼š
            
            # æ£€æŸ¥pending bufferçŠ¶æ€
            pending_updates = len(self.pending_updates.get(symbol, []))
            
            # å…³é”®éªŒè¯ç‚¹4ï¼šå¦‚æœpending bufferè¿‡é•¿ï¼Œè¯´æ˜æ•°æ®å¤„ç†æœ‰é—®é¢˜
            if pending_updates > self.PENDING_RESYNC_THRESHOLD:
                critical_issues.append(f"pending bufferè¿‡é•¿: {pending_updates}ä¸ªæ›´æ–°ç­‰å¾…å¤„ç†")
            
            # å…³é”®éªŒè¯ç‚¹5ï¼šéªŒè¯æ•°æ®çš„æ—¶é—´æˆ³åˆç†æ€§
            if hasattr(local_ob, 'server_timestamp'):
                current_time = int(time.time() * 1000)
                time_diff = current_time - local_ob.server_timestamp
                
                if time_diff > 60000:  # è¶…è¿‡1åˆ†é’Ÿ
                    critical_issues.append(f"æ•°æ®å»¶è¿Ÿè¿‡å¤§: {time_diff}ms")
                elif time_diff > 10000:  # è¶…è¿‡10ç§’
                    warnings.append(f"æ•°æ®æœ‰ä¸€å®šå»¶è¿Ÿ: {time_diff}ms")  

            # å…³é”®éªŒè¯ç‚¹6ï¼šç­–ç•¥å…³é”®ä¸€è‡´æ€§ï¼ˆprice onlyï¼‰
            # âš ï¸ åªæœ‰åœ¨æœ¬åœ°ä¸å¿«ç…§å‡ ä¹åŒæ­¥æ—¶æ‰æ£€æŸ¥æœ€ä¼˜ä»·ä¸€è‡´æ€§
            PRICE_CHECK_MAX_UPDATE_DIFF = 5  # <= 5 ä¸ª update è®¤ä¸ºæ˜¯â€œåŒæ­¥â€
            update_id_diff = update_id_info['update_id_diff']

            price_mismatch = False
            if abs(update_id_diff) <= PRICE_CHECK_MAX_UPDATE_DIFF:
                if snapshot_bids and local_ob.bids:
                    if local_ob.bids[0].price != max(snapshot_bids.keys()):
                        price_mismatch = True

                if snapshot_asks and local_ob.asks:
                    if local_ob.asks[0].price != min(snapshot_asks.keys()):
                        price_mismatch = True

                if price_mismatch:
                    critical_issues.append("æœ€ä¼˜ä»·ä½ä¸å¿«ç…§ä¸ä¸€è‡´ï¼ˆåŒæ­¥çŠ¶æ€ä¸‹ï¼‰")
            else:
                logger.info(
                    f"è·³è¿‡æœ€ä¼˜ä»·ä¸€è‡´æ€§æ ¡éªŒï¼šlocal æ¯” snapshot æ–° {update_id_diff} ä¸ªæ›´æ–°"
                )    

            # ====== ä¸‹é¢éªŒè¯è¾…åŠ©ä¿¡æ¯ ======
            # 7. æ•°é‡ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåªæ£€æŸ¥å­˜åœ¨çš„æ•°æ®ï¼‰
            # å¯¹äºå¿«ç…§ä¸­çš„æ¯ä¸ªä»·æ ¼æ¡£ä½ï¼Œå¦‚æœæœ¬åœ°ä¹Ÿæœ‰ï¼Œæ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
            # 8. æ•°é‡ä¸€è‡´æ€§æ£€æŸ¥
            matched_bids = 0
            matched_asks = 0
            checked_prices = set()
            MAX_ACCEPTABLE_QTY_DIFF = tolerance * 100          # 0.1%
            MAX_WARNING_QTY_DIFF = tolerance * 100 * 5         # 0.5%

            # æ ¹æ®æ›´æ–°IDå·®å¼‚è°ƒæ•´æœŸæœ›åŒ¹é…ç‡
            if update_id_diff == 0:
                EXPECTED_MATCH_RATE = 0.8  # 80%
            elif update_id_diff < 100:
                EXPECTED_MATCH_RATE = 0.6  # 60%
            else:
                EXPECTED_MATCH_RATE = 0.4  # 40%

            # æ£€æŸ¥æœ¬åœ°ä¹°ç›˜æ¡£ä½æ˜¯å¦åœ¨å¿«ç…§ä¸­
            for local_price, local_qty in local_bids.items():
                snapshot_qty = snapshot_bids.get(local_price)
                if snapshot_qty is not None:
                    matched_bids += 1
                    checked_prices.add(local_price)
                    if snapshot_qty != Decimal('0') and local_qty != Decimal('0'):
                        qty_diff_pct = abs(float(snapshot_qty - local_qty) / float(snapshot_qty)) * 100
                        if qty_diff_pct > MAX_WARNING_QTY_DIFF:
                            warnings.append(f"bid {local_price}: æ•°é‡ä¸¥é‡å·®å¼‚ {qty_diff_pct:.2f}% (å¿«ç…§: {snapshot_qty}, æœ¬åœ°: {local_qty})")
                        elif qty_diff_pct > MAX_ACCEPTABLE_QTY_DIFF:
                            differences.append(f"bid {local_price}: æ•°é‡è½»å¾®å·®å¼‚ {qty_diff_pct:.2f}% (å¿«ç…§: {snapshot_qty}, æœ¬åœ°: {local_qty})")

            # æ£€æŸ¥æœ¬åœ°å–ç›˜æ¡£ä½æ˜¯å¦åœ¨å¿«ç…§ä¸­
            for local_price, local_qty in local_asks.items():
                snapshot_qty = snapshot_asks.get(local_price)
                if snapshot_qty is not None:
                    matched_asks += 1
                    checked_prices.add(local_price)
                    if snapshot_qty != Decimal('0') and local_qty != Decimal('0'):
                        qty_diff_pct = abs(float(snapshot_qty - local_qty) / float(snapshot_qty)) * 100
                        if qty_diff_pct > MAX_WARNING_QTY_DIFF:
                            warnings.append(f"ask {local_price}: æ•°é‡ä¸¥é‡å·®å¼‚ {qty_diff_pct:.2f}% (å¿«ç…§: {snapshot_qty}, æœ¬åœ°: {local_qty})")
                        elif qty_diff_pct > MAX_ACCEPTABLE_QTY_DIFF:
                            differences.append(f"ask {local_price}: æ•°é‡è½»å¾®å·®å¼‚ {qty_diff_pct:.2f}% (å¿«ç…§: {snapshot_qty}, æœ¬åœ°: {local_qty})")

            # 9. éªŒè¯åŒ¹é…çš„ä»·æ ¼æ¡£ä½æ•°é‡
            matched_levels = len(checked_prices)
            total_snapshot_levels = len(snapshot_bids) + len(snapshot_asks)
            total_local_levels = len(local_bids) + len(local_asks)

            logger.info(f"åŒ¹é…ç»Ÿè®¡: æœ¬åœ°{total_local_levels}æ¡£, åŒ¹é…{matched_levels}æ¡£, å¿«ç…§{total_snapshot_levels}æ¡£")
            logger.info(f"ä¹°ç›˜åŒ¹é…: {matched_bids}/{len(local_bids)}, å–ç›˜åŒ¹é…: {matched_asks}/{len(local_asks)}")
            logger.info(f"æ›´æ–°IDå·®å¼‚: {update_id_diff}")

            # æ£€æŸ¥åŒ¹é…ç‡
            if len(local_bids) > 0:
                bid_match_rate = matched_bids / len(local_bids)
                if bid_match_rate < EXPECTED_MATCH_RATE:
                    differences.append(f"ä¹°ç›˜åŒ¹é…ç‡{bid_match_rate:.1%}ä½äºé¢„æœŸ{EXPECTED_MATCH_RATE:.0%}")
                    if bid_match_rate < 0.2:
                        warnings.append(f"ä¹°ç›˜åŒ¹é…ä¸¥é‡ä¸è¶³: {bid_match_rate:.1%}")

            if len(local_asks) > 0:
                ask_match_rate = matched_asks / len(local_asks)
                if ask_match_rate < EXPECTED_MATCH_RATE:
                    differences.append(f"å–ç›˜åŒ¹é…ç‡{ask_match_rate:.1%}ä½äºé¢„æœŸ{EXPECTED_MATCH_RATE:.0%}")
                    if ask_match_rate < 0.2:
                        warnings.append(f"å–ç›˜åŒ¹é…ä¸¥é‡ä¸è¶³: {ask_match_rate:.1%}")

            # æ£€æŸ¥å¿«ç…§æ•°æ®å®Œæ•´æ€§
            if total_snapshot_levels < 200:  # é¢„æœŸæ˜¯200æ¡£ï¼ˆ100ä¹°+100å–ï¼‰
                warnings.append(f"å¿«ç…§æ•°æ®ä¸å®Œæ•´: åªè·å–äº†{total_snapshot_levels}æ¡£ï¼ˆé¢„æœŸ200æ¡£ï¼‰")
                if total_snapshot_levels < 100:
                    logger.warning("å¿«ç…§æ•°æ®ä¸¥é‡ä¸è¶³ï¼ŒéªŒè¯å¯èƒ½ä¸å¯é ")

            
            # 10. ä¸¥é‡æ€§åˆ¤æ–­
            # æ ¹æ®æ›´æ–°IDå·®å¼‚è°ƒæ•´éªŒè¯ä¸¥æ ¼åº¦
            update_id_diff = update_id_info['update_id_diff']
            
            if update_id_diff > 0:
                # æœ¬åœ°æ•°æ®æ¯”å¿«ç…§æ–°ï¼Œå…è®¸æ•°é‡å·®å¼‚ï¼ˆè¿™æ˜¯æ­£å¸¸çš„å¸‚åœºå˜åŒ–ï¼‰
                # åªæ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡é—®é¢˜ï¼Œä¸æ£€æŸ¥æ™®é€šæ•°é‡å·®å¼‚
                is_valid = len(critical_issues) == 0   
                logger.info(f"æœ¬åœ°æ•°æ®æ¯”å¿«ç…§æ–° {update_id_diff} ä¸ªæ›´æ–°ï¼Œå…è®¸æ•°é‡å·®å¼‚")
            else:
                # æœ¬åœ°æ•°æ®ä¸å¿«ç…§åŒæ­¥ï¼Œåº”è¯¥ä¸¥æ ¼æ£€æŸ¥
                is_valid = len(critical_issues) == 0 and len(warnings) == 0

            # æ„å»ºç»“æœ
            result = {
                'reason': 'verification_completed',
                'is_valid': is_valid,
                'critical_issues': critical_issues,
                'differences': differences,
                'warnings': warnings,
                'update_id_info': update_id_info,
                'pending_updates': pending_updates,
                'local_bids_count': len(local_bids),
                'local_asks_count': len(local_asks),
                'snapshot_bids_count': len(snapshot_bids),
                'snapshot_asks_count': len(snapshot_asks),
                'matched_price_levels': matched_levels,
                'data_timestamp': local_ob.server_timestamp if hasattr(local_ob, 'server_timestamp') else None,
                'snapshot_update_id': snapshot_last_update_id,
                'local_update_id': local_last_update_id,
                'local_data_newer': update_id_diff > 0,
            }    

            # æ›´æ–°éªŒè¯ç»Ÿè®¡
            self._update_verification_stats(symbol, is_valid, result)
            
            return is_valid, result
            
        except Exception as e:
            logger.error(f"è®¢å•ç°¿éªŒè¯å‡ºé”™: {e}", exc_info=True)
            error_details = {
                'reason': 'verification_error', 
                'error': str(e), 
                'traceback': traceback.format_exc()
            }
            # æ›´æ–°éªŒè¯ç»Ÿè®¡
            self._update_verification_stats(symbol, False, error_details)
            return False, error_details
    
    def start_verification(self, symbol: str, interval_seconds: int = 60):
        """å¯åŠ¨æŒç»­éªŒè¯ä»»åŠ¡"""
        symbol = symbol.upper()
        
        async def verification_loop():
            while True:
                await asyncio.sleep(interval_seconds)

                if not self.is_connected:
                    logger.info(f"è¿æ¥æ–­å¼€ï¼Œæš‚åœéªŒè¯: {symbol}")
                    # ç­‰å¾…è¿æ¥æ¢å¤
                    while not self.is_connected:
                        await asyncio.sleep(1)
                    logger.debug(f"è¿æ¥æ¢å¤ï¼Œç»§ç»­éªŒè¯: {symbol}")
                
                is_valid, details = await self.verify_orderbook_snapshot(symbol)
                
                # ä» update_id_info ä¸­è·å–æ›´æ–°ID
                update_id_info = details.get('update_id_info', {})
                local_update_id = update_id_info.get('local_last_update_id', 'N/A')
                snapshot_update_id = update_id_info.get('snapshot_update_id', 'N/A')
                
                if is_valid:
                    logger.info(f"âœ… è®¢å•ç°¿éªŒè¯é€šè¿‡: {symbol} "
                            f"(æœ¬åœ°æ›´æ–°ID: {local_update_id}, å¿«ç…§æ›´æ–°ID: {snapshot_update_id})")
                else:
                    logger.warning(f"âš ï¸ è®¢å•ç°¿éªŒè¯å¤±è´¥: {symbol}, åŸå› : {details.get('reason')}")
                    if 'differences' in details and details['differences']:
                        logger.warning(f"å·®å¼‚è¯¦æƒ…:")
                        for diff in details['differences'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªå·®å¼‚
                            logger.warning(f"  - {diff}")
                    
                    # å¦‚æœæ•°æ®ä¸¥é‡ä¸ä¸€è‡´ï¼Œå¯ä»¥è§¦å‘é‡æ–°åŒæ­¥
                    if details.get('reason') in ['local_data_older', 'local_orderbook_missing', 'missing_updates_after_snapshot']:
                        logger.critical(f"æ•°æ®ä¸¥é‡ä¸ä¸€è‡´: {symbol}")
                        # å¯ä»¥è€ƒè™‘è§¦å‘é‡æ–°åŒæ­¥
                        # await self._init_snapshot_with_buffering(symbol)
        
        # å¯åŠ¨éªŒè¯ä»»åŠ¡
        self._verification_tasks[symbol] = asyncio.create_task(verification_loop())
        logger.info(f"å·²å¯åŠ¨ {symbol} çš„éªŒè¯ä»»åŠ¡ï¼Œé—´éš”: {interval_seconds}ç§’")

    def _update_verification_stats(self, symbol: str, is_valid: bool, details: Dict):
        """æ›´æ–°éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        if symbol not in self._verification_stats:
            self._verification_stats[symbol] = {
                'total_verifications': 0,
                'passed_verifications': 0,
                'failed_verifications': 0,
                'last_verification_time': None,
                'last_verification_result': None,
            }
        
        stats = self._verification_stats[symbol]
        stats['total_verifications'] += 1
        
        if is_valid:
            stats['passed_verifications'] += 1
        else:
            stats['failed_verifications'] += 1
        
        stats['last_verification_time'] = time.time()
        stats['last_verification_result'] = details
        
        logger.debug(f"éªŒè¯ç»Ÿè®¡æ›´æ–°: {symbol} - æ€»è®¡: {stats['total_verifications']}, "
                    f"é€šè¿‡: {stats['passed_verifications']}, å¤±è´¥: {stats['failed_verifications']}")
        
        # è§¦å‘éªŒè¯ç»“æœè®°å½•
        self._record_verification_result(symbol, is_valid, stats)    

    def get_verification_status(self, symbol: str = None) -> Dict:
        """è·å–éªŒè¯çŠ¶æ€"""
        if symbol:
            symbol = symbol.upper()
            stats = self._verification_stats.get(symbol, {})
            total = stats.get('total_verifications', 0)
            passed = stats.get('passed_verifications', 0)
            failed = stats.get('failed_verifications', 0)
            
            # è®¡ç®—æˆåŠŸç‡
            if total > 0:
                success_rate = passed / total
            else:
                success_rate = 0
            
            return {
                'symbol': symbol,
                'verification_enabled': self._verification_enabled,
                'verification_running': symbol in self._verification_tasks,
                'total_verifications': total,
                'passed_verifications': passed,
                'failed_verifications': failed,
                'success_rate': f"{success_rate:.2%}",
                'last_verification_time': stats.get('last_verification_time'),
                'last_verification_result': stats.get('last_verification_result', {}).get('reason'),
            }
        else:
            # è¿”å›æ‰€æœ‰äº¤æ˜“å¯¹çš„æ±‡æ€»ä¿¡æ¯
            all_symbols = list(self._verification_stats.keys())
            
            # è®¡ç®—æ€»ç»Ÿè®¡æ•°æ®
            total_verifications = 0
            total_passed = 0
            total_failed = 0
            
            for stats in self._verification_stats.values():
                total_verifications += stats.get('total_verifications', 0)
                total_passed += stats.get('passed_verifications', 0)
                total_failed += stats.get('failed_verifications', 0)
            
            # è®¡ç®—æ€»æˆåŠŸç‡
            if total_verifications > 0:
                overall_success_rate = total_passed / total_verifications
            else:
                overall_success_rate = 0
            
            return {
                'total_symbols': len(all_symbols),
                'total_verifications': total_verifications,
                'total_passed': total_passed,
                'total_failed': total_failed,
                'overall_success_rate': f"{overall_success_rate:.2%}",
                'verification_enabled': self._verification_enabled,
                'running_tasks': len(self._verification_tasks),
                'symbols': all_symbols,
            } 
        
    def print_verification_summary(self):
        """æ‰“å°éªŒè¯ç»Ÿè®¡æ‘˜è¦"""
        print("=" * 80)
        print("éªŒè¯ç»Ÿè®¡æ‘˜è¦")
        print("=" * 80)
        
        for symbol, stats in self._verification_stats.items():
            total = stats.get('total_verifications', 0)
            if total > 0:
                passed = stats.get('passed_verifications', 0)
                failed = stats.get('failed_verifications', 0)
                success_rate = passed / total
                
                print(f"{symbol}:")
                print(f"  æ€»è®¡éªŒè¯: {total}")
                print(f"  é€šè¿‡: {passed} ({success_rate:.2%})")
                print(f"  å¤±è´¥: {failed}")
                print(f"  æœ€åéªŒè¯æ—¶é—´: {stats.get('last_verification_time')}")
                print(f"  æœ€åç»“æœ: {stats.get('last_verification_result', {}).get('reason')}")
                print()


    def is_symbol_ready(self, symbol: str) -> bool:
        """æ£€æŸ¥symbolæ˜¯å¦å·²æˆåŠŸåˆå§‹åŒ–"""
        return self.snapshot_initialized.get(symbol.upper(), False)
    
    def get_last_trade(self, symbol: str) -> Optional[TradeTick]:
        """è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„æœ€æ–°äº¤æ˜“"""
        return self.last_trade.get(symbol.upper())
    
    def get_recent_trades(self, symbol: str, limit: int = 50) -> List[TradeTick]:
        """è·å–æŒ‡å®šäº¤æ˜“å¯¹çš„æœ€è¿‘äº¤æ˜“è®°å½•"""
        symbol = symbol.upper()
        if symbol not in self.recent_trades:
            return []
        
        # è¿”å›æœ€è¿‘çš„limitæ¡äº¤æ˜“è®°å½•
        trades = list(self.recent_trades[symbol])
        return trades[-limit:] if len(trades) > limit else trades
    
    def get_trade_statistics(self, symbol: str, window_seconds: int = 300) -> Dict[str, Any]:
        """
        è·å–äº¤æ˜“ç»Ÿè®¡ä¿¡æ¯ï¼ˆæœ€è¿‘window_secondsç§’å†…çš„ç»Ÿè®¡ï¼‰
        """
        symbol = symbol.upper()
        if symbol not in self.recent_trades:
            return {}
        
        now_timestamp = int(datetime.now(timezone.utc).timestamp() * 1000)
        window_millis = window_seconds * 1000
        
        # è¿‡æ»¤çª—å£æœŸå†…çš„äº¤æ˜“
        recent_trades = [
            trade for trade in self.recent_trades[symbol]
            if now_timestamp - trade.server_timestamp <= window_millis
        ]
        
        if not recent_trades:
            return {}
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        buy_trades = [t for t in recent_trades if t.side == "BUY"]
        sell_trades = [t for t in recent_trades if t.side == "SELL"]
        
        total_volume = sum(float(t.size) for t in recent_trades)
        buy_volume = sum(float(t.size) for t in buy_trades)
        sell_volume = sum(float(t.size) for t in sell_trades)
        
        prices = [float(t.price) for t in recent_trades]
        
        return {
            "symbol": symbol,
            "window_seconds": window_seconds,
            "trade_count": len(recent_trades),
            "buy_count": len(buy_trades),
            "sell_count": len(sell_trades),
            "total_volume": total_volume,
            "buy_volume": buy_volume,
            "sell_volume": sell_volume,
            "volume_ratio": float(buy_volume / sell_volume) if sell_volume > 0 else float('inf'),
            "avg_price": sum(prices) / len(prices) if prices else 0,
            "min_price": min(prices) if prices else 0,
            "max_price": max(prices) if prices else 0,
            "last_price": float(recent_trades[-1].price) if recent_trades else 0,
        }